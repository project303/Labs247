{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab Extra 04 - Sentiment Analytics TF-IDF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilmpXQZHvzFH"
      },
      "source": [
        "## Library Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEIEqiOdfA_3",
        "outputId": "160a105a-863b-45f6-e62e-0d187b1d3130"
      },
      "source": [
        "import re\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.classify import SklearnClassifier\n",
        "\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from subprocess import check_output\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riMK50i_qgi9",
        "outputId": "4d58014c-04e9-4ef0-f5ba-cbdb0ce1ee5f"
      },
      "source": [
        "!pip install sastrawi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sastrawi in /usr/local/lib/python3.7/dist-packages (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOb0Jps6qj-B"
      },
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8onz3TnaGW2C"
      },
      "source": [
        "#augment the stopwords with nonstandard twitter words\n",
        "stopwords_set = set(stopwords.words(\"indonesian\"))\n",
        "stopwords_aug = {\"ya\",\"yak\",\"iya\",\"yg\",\"ga\",\"gak\",\"gk\",\"udh\",\"sdh\",\"udah\",\"dah\",\"nih\",\"ini\",\"deh\",\"sih\",\"dong\",\"donk\",\n",
        "                 \"sm\",\"knp\",\"utk\",\"yaa\",\"tdk\",\"gini\",\"gitu\",\"bgt\",\"gt\",\"nya\",\"kalo\",\"cb\",\"jg\",\"jgn\",\"gw\",\"ge\",\n",
        "                 \"sy\",\"min\",\"mas\",\"mba\",\"mbak\",\"pak\",\"kak\",\"trus\",\"trs\",\"bs\",\"bisa\",\"aja\",\"saja\",\"no\",\n",
        "                 \"w\",\"g\",\"gua\",\"gue\",\"emang\",\"emg\",\"wkwk\",\"dr\",\"kau\",\"dg\",\"gimana\",\"apapun\",\"apa\",\n",
        "                 \"klo\",\"yah\",\"banget\",\"pake\",\"terus\",\"krn\",\"jadi\",\"jd\",\"mu\",\"ku\",\"si\",\"hehe\",\n",
        "                 \"tp\",\"pa\",\"lu\",\"lo\",\"lw\",\"tw\",\"tau\",\"karna\",\"kayak\",\"ky\",\"lg\",\"untuk\",\"tuk\",\"dg\",\"dgn\"}\n",
        "stopwords_all = stopwords_set.union(stopwords_aug)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P9Qjvono_nV"
      },
      "source": [
        "def clean_text(text):\n",
        "    filtered_tokens = \"\"\n",
        "    for token in text:\n",
        "      if re.search('[a-zA-Z\\s]', token):\n",
        "        filtered_tokens = filtered_tokens + token.lower()\n",
        "        \n",
        "    return filtered_tokens\n",
        "\n",
        "def tokenize_clean(text):\n",
        "    \n",
        "    #tokenisasi\n",
        "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word\n",
        "        in nltk.word_tokenize(sent)]\n",
        "    \n",
        "    #clean token from numeric and other character like puntuation\n",
        "    filtered_tokens = []\n",
        "    for token in tokens:\n",
        "        if re.search('[a-zA-Z]', token):\n",
        "            filtered_tokens.append(token)\n",
        "            \n",
        "    return filtered_tokens\n",
        "\n",
        "def remove_stopwords(tokenized_text):\n",
        "    \n",
        "    cleaned_token = []\n",
        "    for token in tokenized_text:\n",
        "        if token not in stopwords_all:\n",
        "            cleaned_token.append(token)\n",
        "            \n",
        "    return cleaned_token\n",
        "\n",
        "def stemming_text(tokenized_text):\n",
        "    \n",
        "    #stem using Sastrawi StemmerFactory \n",
        "    factory = StemmerFactory()\n",
        "    stemmer = factory.create_stemmer()\n",
        "\n",
        "    stems = []\n",
        "    for token in tokenized_text:\n",
        "        stems.append(stemmer.stem(token))\n",
        "\n",
        "    return stems\n",
        "\n",
        "def text_preprocessing(text):\n",
        "    #tokenize, remove non alpha numeric and make lower\n",
        "    text_tmp = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    text_tmp = text_tmp.lower()\n",
        "    text_tmp = text_tmp.split()\n",
        "    \n",
        "    #remove stopwords\n",
        "    prep02 = remove_stopwords(text_tmp)\n",
        "    \n",
        "    #stemmingnya lambat banget\n",
        "    #prep03 = stemming_text(prep01)\n",
        "\n",
        "    prep03 = ' '.join(prep02)\n",
        "            \n",
        "    return prep03"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNBfQVepGWoQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvM7_X5Ivtbd"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icVVtmrxfk5s",
        "outputId": "4bb0f200-4191-49dd-b3bf-f0b9b29fe26b"
      },
      "source": [
        "!mkdir -p dataset\n",
        "!wget https://raw.githubusercontent.com/project303/dataset/master/Twitter.csv -P dataset"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-28 04:38:08--  https://raw.githubusercontent.com/project303/dataset/master/Twitter.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 413468 (404K) [text/plain]\n",
            "Saving to: ‘dataset/Twitter.csv.1’\n",
            "\n",
            "\rTwitter.csv.1         0%[                    ]       0  --.-KB/s               \rTwitter.csv.1       100%[===================>] 403.78K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-07-28 04:38:09 (11.0 MB/s) - ‘dataset/Twitter.csv.1’ saved [413468/413468]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_6xbIApfqu8",
        "outputId": "cd4cd000-57b6-4d34-bdaf-d4d3e9d59b76"
      },
      "source": [
        "dataset = pd.read_csv('dataset/Twitter.csv', sep='|')\n",
        "\n",
        "len(dataset)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4294"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dlSwgdVUGzt3",
        "outputId": "d58542b0-d5ad-4a0c-db30-4f96f094896b"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>715600523756314626</td>\n",
              "      <td>@IndosatCare iya nomernya masih itu. Mksh.</td>\n",
              "      <td>Positif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>715599778948599808</td>\n",
              "      <td>@IndosatCare udah di DM yah</td>\n",
              "      <td>Positif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>704874550631145472</td>\n",
              "      <td>@Telkomsel aku pakai loop kak :)</td>\n",
              "      <td>Positif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>704875356910563328</td>\n",
              "      <td>@rikawidjaya04 Terima kasih juga Kak Rika atas...</td>\n",
              "      <td>Positif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>713428238458953732</td>\n",
              "      <td>@ndusell saya simpati tan</td>\n",
              "      <td>Positif</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   id  ... sentiment\n",
              "0  715600523756314626  ...   Positif\n",
              "1  715599778948599808  ...   Positif\n",
              "2  704874550631145472  ...   Positif\n",
              "3  704875356910563328  ...   Positif\n",
              "4  713428238458953732  ...   Positif\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfmHJ7z8G29K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGuzoHjdwEv3"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRPXPYnNG6Dm"
      },
      "source": [
        "dataset = dataset[dataset.sentiment != \"Netral\"]\n",
        "tweets = np.array(dataset['text'])\n",
        "sentiments = np.array(dataset['sentiment'])\n",
        "\n",
        "train_data, test_data, train_label, test_label = train_test_split(tweets, sentiments, test_size=0.2, random_state=4)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXMSdZYoH95A",
        "outputId": "5d43e89c-37ab-470a-cfc6-f6eee2bd42d4"
      },
      "source": [
        "train_label[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Positif', 'Positif', 'Negatif', 'Positif', 'Negatif', 'Negatif',\n",
              "       'Positif', 'Negatif', 'Positif', 'Positif'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JalHwtH4hZgc",
        "outputId": "890111de-ec40-4d89-dd42-92e53f3161f9"
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2092"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7g2ggTeOiXZ"
      },
      "source": [
        "train_data_clean = []\n",
        "\n",
        "for tweet_text in train_data:\n",
        "  train_data_clean.append(text_preprocessing(tweet_text))\n",
        "\n",
        "test_data_clean = []\n",
        "for tweet_text in test_data:\n",
        "  test_data_clean.append(text_preprocessing(tweet_text))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z61IwycwIqd7",
        "outputId": "bbf661de-7789-442b-e00e-9bd329406146"
      },
      "source": [
        "train_data_clean[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['indosatcare oke terima kasih bantuannya',\n",
              " 'ryamizard kemenhan bentuk tim',\n",
              " 'telkomsel paket telkomsel mahal bnget kartu telkomsel murah mw pakai intrnet kartu pakai',\n",
              " 'ijin',\n",
              " 'indosatcare tolong sms diblok pulsa kepotong',\n",
              " 'indosatcare sya cek kuota ok dpt sms saldo kuota super internet cek status paket',\n",
              " 'operasi militer menteri pertahanan ryamizard ryacudu pertimbangan matang',\n",
              " 'telkomsel grapari pondok gede buka jam sim card hang',\n",
              " 'emenhan kebutuhan bandan intelijen pertahanan metro tv news',\n",
              " 'telkomsel info tunggu thx']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbKvjddJwlrc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R1kMeNGwl_g"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV1USBuXIwDV"
      },
      "source": [
        "# build TFIDF features on train reviews\n",
        "tv = TfidfVectorizer( ngram_range=(1,1),\n",
        "                     analyzer='word',\n",
        "                     lowercase=True,\n",
        "                     sublinear_tf=True,\n",
        "                     use_idf=True\n",
        "                     )\n",
        "tv_train_features = tv.fit_transform(train_data_clean)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VJnbHF3P1d1",
        "outputId": "59d009b7-3210-43b3-98e5-dad53e3b0c69"
      },
      "source": [
        "len(tv.get_feature_names())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4045"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz49NaQbPrMg",
        "outputId": "5aa25b76-8772-4eb2-91bf-f33a20638a98"
      },
      "source": [
        "tv_train_features.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2092, 4045)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI4SG8lVahBP"
      },
      "source": [
        "tv_test_features = tv.transform(test_data_clean)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYBsal1NateB",
        "outputId": "d3c5a604-d269-4d6a-fd80-b642d52f54a3"
      },
      "source": [
        "tv_test_features.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(524, 4045)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhnenZX2at1k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeeRH5Hmwz0j"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLdP8aE_bTHV"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "\n",
        "model_lr = LogisticRegression(penalty='l2', max_iter=1000, C=1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COSvppmUb3X7",
        "outputId": "56367740-9da6-43e9-e2f2-dd2fcb0ef433"
      },
      "source": [
        "# build model    \n",
        "model_lr.fit(tv_train_features, train_label)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IppoG1CctgX"
      },
      "source": [
        "predictions_lr = model_lr.predict(tv_test_features) "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dstgUIivhevH",
        "outputId": "da3f5e7d-fb43-45d1-a2c4-1f5c5edd9466"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "neg_cnt = 0\n",
        "pos_cnt = 0\n",
        "neg_cnt_x = 0\n",
        "pos_cnt_x = 0\n",
        "\n",
        "for i in range(0, len(test_label)):\n",
        "  if test_label[i] == 'Positif':\n",
        "    pos_cnt = pos_cnt + 1\n",
        "    if test_label[i] == predictions_lr[i]:\n",
        "      pos_cnt_x = pos_cnt_x + 1\n",
        "  else:\n",
        "    neg_cnt = neg_cnt + 1\n",
        "    if test_label[i] == predictions_lr[i]:\n",
        "      neg_cnt_x = neg_cnt_x + 1\n",
        "\n",
        "print(neg_cnt)\n",
        "print(pos_cnt)\n",
        "\n",
        "print('[Positif]: %s/%s '  % (pos_cnt,pos_cnt_x))\n",
        "print('[Negatif]: %s/%s '  % (neg_cnt,neg_cnt_x))\n",
        "\n",
        "print(\"Accuracy(in %):\", metrics.accuracy_score(test_label, predictions_lr)*100)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "264\n",
            "260\n",
            "[Positif]: 260/242 \n",
            "[Negatif]: 264/216 \n",
            "Accuracy(in %): 87.40458015267176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w06gSH4om9-A",
        "outputId": "9e617b92-2337-430e-dd6d-a25bedf47ed7"
      },
      "source": [
        "print('Accuracy \\t: ', np.round( metrics.accuracy_score(test_label, predictions_lr), 4))\n",
        "print('Precision \\t: ', np.round(metrics.precision_score(test_label, \n",
        "                                                     predictions_lr,\n",
        "                                                     average='weighted'), 4))\n",
        "print('Recall  \\t: ', np.round( metrics.recall_score(test_label,\n",
        "                                                    predictions_lr,\n",
        "                                                    average='weighted'), 4))\n",
        "print('F1 Score  \\t: ', np.round( metrics.f1_score(test_label, \n",
        "                                                  predictions_lr,\n",
        "                                                  average='weighted'), 4))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy \t:  0.874\n",
            "Precision \t:  0.8791\n",
            "Recall  \t:  0.874\n",
            "F1 Score  \t:  0.8737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atGTuLNiddII"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfBqrQyyaY4I",
        "outputId": "98655007-f0c3-4e84-980a-a19ed492393a"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "model_nb = MultinomialNB()\n",
        "model_nb.fit(tv_train_features, train_label)\n",
        "predict_nb = model_nb.predict(tv_test_features)\n",
        "print(\"Accuracy(in %):\", metrics.accuracy_score(test_label, predict_nb)*100)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy(in %): 85.30534351145039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l681WDbRqpSu",
        "outputId": "7324159c-4fd2-4449-800e-e8585538a1d4"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "model_svm = SVC(kernel = 'linear', random_state = 0)\n",
        "model_svm.fit(tv_train_features, train_label)\n",
        "predict_svm = model_svm.predict(tv_test_features)\n",
        "print(\"Accuracy(in %):\", metrics.accuracy_score(test_label, predict_svm)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy(in %): 91.41221374045801\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqtYFXQ3oXPo",
        "outputId": "4f482d20-e1b6-41bc-994b-8361ff9001cf"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model_rf = RandomForestClassifier(n_estimators = 500, criterion = 'entropy', random_state = 0)\n",
        "model_rf.fit(tv_train_features, train_label)\n",
        "predict_rf = model_rf.predict(tv_test_features)\n",
        "print(\"Accuracy(in %):\", metrics.accuracy_score(test_label, predict_rf)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy(in %): 89.12213740458014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOUw1_g_qx2i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkHZMz6orbrD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5XlixC22Dis"
      },
      "source": [
        "## Prediction Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ48D_Oa5BeE"
      },
      "source": [
        "def Predict_Sentiment(text, model):\n",
        "  data_txt =[]\n",
        "  data_txt.append(text_preprocessing(text))\n",
        "  feature_p = tv.transform(data_txt) \n",
        "  predict_p = model.predict(feature_p)\n",
        "\n",
        "  return predict_p[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fsam9OWM1u2p",
        "outputId": "5fb0c825-6c5a-4e44-9522-815d8be70474"
      },
      "source": [
        "Predict_Sentiment('Telkomsel sinyal jelek', model_svm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Negatif'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    }
  ]
}